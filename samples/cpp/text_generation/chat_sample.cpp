// Copyright (C) 2023-2024 Intel Corporation
// SPDX-License-Identifier: Apache-2.0

#include "openvino/genai/llm_pipeline.hpp"
#include <string>
#include <iostream>
#include <fstream>

#ifdef _WIN32
#include <Windows.h>
#include <io.h>
#else
#include <unistd.h>
#endif

int main(int argc, char* argv[]) try {
#ifdef _WIN32
    SetConsoleOutputCP(CP_UTF8);
    system("chcp 65001"); //Using UTF-8 Encoding
#endif
    if (3 != argc) {
        throw std::runtime_error(std::string{ "Usage: " } + argv[0] + " <MODEL_DIR>" + "<DEVICE>");
    }
    std::string prompt;
    //std::string models_path = "/home/openvino/workspaces/AIGC/honor/release_mem/openvino.genai/glm4-1p5b-sft-v6-int4-asym-ov-gs64-awq/";
    std::string models_path = argv[1];


    //std::string device = "CPU";  // GPU, NPU can be used as well
    std::string device = argv[2];
    //ov::genai::LLMPipeline pipe(models_path, device);

    ov::genai::GenerationConfig config;
    config.max_new_tokens = 500;
    config.do_sample = false;
    config.top_k = 50;
    config.top_p = 0.1;
    config.stop_token_ids = { 59246, 59253,59255 };
    //config.temperature = 0.1;

    std::function<bool(std::string)> streamer = [](std::string word) {
        std::cout << word << std::flush;
        // Return flag corresponds whether generation should be stopped.
        // false means continue generation.
        return false;
        };

    std::cout << "question:\n";
    //prompt = "è¯·æ€»ç»“ä¸‹é¢çš„æ–‡æ¡£ï¼Œè¾“å‡ºæ‘˜è¦å’Œå…³é”®è¯:IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 1Joint Attention-Guided Feature Fusion Network forSaliency Detection of Surface DefectsXiaoheng Jiang, Feng Yan, Yang Lu, Ke Wang, Shuai GuoTianzhu Zhang, Yanwei Pang, Senior Member, IEEE, Jianwei Niu, Senior Member, IEEE, and Mingliang XuAbstractâ€”Surface defect inspection plays an important role inthe process of industrial manufacture and production. ThoughConvolutional Neural Network (CNN) based defect inspectionmethods have made huge leaps, they still confront a lot ofchallenges such as defect scale variation, complex background,low contrast, and so on. To address these issues, we proposea joint attention-guided feature fusion network (JAFFNet) forsaliency detection of surface defects based on the encoder-decodernetwork. JAFFNet mainly incorporates a joint attention-guidedfeature fusion (JAFF) module into decoding stages to adaptivelyfuse low-level and high-level features. The JAFF module learns toemphasize defect features and suppress background noise duringfeature fusion, which is beneficial for detecting low-contrastdefects. In addition, JAFFNet introduces a dense receptive field(DRF) module following the encoder to capture features with richcontext information, which helps detect defects of different scales.The JAFF module mainly utilizes a learned joint channel-spatialattention map provided by high-level semantic features to guidefeature fusion. The attention map makes the model pay moreattention to defect features. The DRF module utilizes a sequenceof multi-receptive-field (MRF) units with each taking as inputsall the preceding MRF feature maps and the original input. Theobtained DRF features capture rich context information with alarge range of receptive fields. Extensive experiments conductedon SD-saliency-900, Magnetic tile, and DAGM 2007 indicate thatour method achieves promising performance in comparison withother state-of-the-art methods. Meanwhile, our method reachesa real-time defect detection speed of 66 FPS.Index Termsâ€”Feature fusion, channel-spatial attention, densereceptive field, saliency detection, surface defects.This work was supported in part by National Key R&D Program of Chinaunder Grant 2021YFB3301504, in part by the National Natural Science Foun-dation of China under Grant 62172371, U21B2037, 62036010, 62102370,61903341, 62106232, in part by China Postdoctoral Science Foundation underGrant 2021TQ0301, and in part by Foundation for University Key Researchof Henan Province (21A520040, 21A520002), Hangzhou Innovation Institute,Beihang University (NO. 2020-Y4-A-020), and CAAI-Huawei MindSporeOpenFund. (Corresponding author: Jianwei Niu, Mingliang Xu .)Xiaoheng Jiang, Yang Lu, Ke Wang, Shuai Guo, and Mingliang Xu arewith the School of Computer and Artificial Intelligence, Zhengzhou Univer-sity, Engineering Research Center of Intelligent Swarm Systems, Ministryof Education, National Supercomputing Center in Zhengzhou, Zhengzhou450001, China (e-mail: jiangxiaoheng@zzu.edu.cn; ieylu@zzu.edu.cn; iek-wang@zzu.edu.cn; iesguo@zzu.edu.cn; iexumingliang@zzu.edu.cn).Feng Yan is with the School of Computer and Artificial Intelligence,Zhengzhou University, Zhengzhou 450001, China (ieyanfeng@163.com).Tianzhu Zhang is with the School of Information Science and Technology,University of Science and Technology of China, Hefei 230026, China (e-mail:tzzhang@ustc.edu.cn).Yanwei Pang is with the School of Electrical Automation and Infor-mation Engineering, Tianjin University, Tianjin 300072, China (e-mail:pyw@tju.edu.cn).Jianwei Niu is with the State Key Laboratory of Virtual Reality Technologyand Systems, School of Computer Science and Engineering, Beihang Univer-sity, Beijing 100191, China, and Hangzhou Innovation Institute of BeihangUniversity, Hangzhou 310051, China (e-mail: niujianwei@buaa.edu.cn).Fig. 1. Challenges of surface defect inspection. (a) and (b) defects withdifferent scales. (c) defects with low contrast. (a) and (d) interference factorsin the background. The defects and interference factors are represented by redand yellow rectangles, respectively.I. I NTRODUCTIONSURFACE defect inspection is a key task in the process ofindustrial production and is essential for product qualitycontrol. Compared with the manual defect inspection methods,computer vision based automatic defect inspection technolo-gies have become more popular in industrial production due totheir superior defect inspection performance with faster speedand higher accuracy.Traditional defect inspection approaches generally considerthe surface defect inspection as a texture analysis issue and ex-ploit several classic strategies such as texture filters [1], texturestatistics [2], [3], texture modeling [4], and texture structure[5]. These methods rely heavily on specific texture informationand work well when the defects are simple. However, the sur-face defects in real industrial scenes usually exhibit complexityand diversity in appearance and scale, which brings a hugechallenge for accurate defect inspection. Fig. 1 demonstratesseveral typical issues about surface defect inspection, includingscale variation, low contrast, and background interference. Thered and yellow rectangles in Fig. 1 represent the defects andbackground interference, respectively. Fig. 1 (a) and (b) showarXiv:2402.02797v1 [cs.CV] 5 Feb 2024IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 2that the defects vary largely in scale. Some surface defectsare very small and have less than 80 pixels in a 256 Ã— 256image, as shown in Fig. 1 (a). Fig. 1 (c) shows the lowcontrast between the defects and the background caused byinappropriate lighting conditions. Fig. 1 (a) and (d) show thatthere exist some interference factors in the background whichare very similar to the defects and are hard to discriminate.Recently, deep learning methods based on convolutionalneural network (CNN) have made great progress in manycomputer vision tasks such as image classification [6]â€“[8],object detection [9]â€“[11], image segmentation [12]â€“[14], andso on. These methods are designed for general objects and cannot directly generalize to surface defect inspection due to theabove mentioned challenges. To handle these challenges, re-searchers have designed CNN-based models that target surfacedefect inspection, such as the region-level defect inspectionmethods [15]â€“[19] and the pixel-level ones [20]â€“[24]. Amongthese works, the pixel-level methods can provide more detailedinformation about defects, such as boundary, shape, and size.Most of these methods adopt the encoder-decoder structure asthe basic backbone, in which the decoder can be regardedas the fusion process of high-level features from the toplayers and low-level features from the corresponding bottomlayers. The high-level features contain more abstract semanticinformation, while the low-level features contain more finedetails. The combination of the two-level features is beneficialto defect inspection. However, these methods still suffer froma certain amount of inspection errors when the defects showweak appearances, which are usually characterized by lowcontrast, small area, or subtle scratch. That is mainly becausethese methods like [21], [22], [24] simply adopt direct additionor concatenation operations to combine low-level and high-level features, in which the features related to defects are proneto be drowned by the background during feature fusion.To solve this problem, we present a joint attention-guidedfeature fusion (JAFF) module, which can adaptively reservefeatures of defects during feature fusion. JAFF first computesa channel-spatial attention map using the high-level featuresand then uses it to refine the corresponding low-level features.Finally, JAFF concatenates the refined low-level features andhigh-level features in channel dimension. The high-level fea-tures are used to generate the attention map based on thefact that they contain rich semantic information about thedefects. As a result, the obtained attention map can emphasizethe most meaningful low-level defect features and suppressbackground noise during feature fusion, resulting in robustdefect-focused features. In addition, context information isalso crucial in defect detection, especially for those defects ofvarious scales. As the scale of defects changes significantly, thesize of the receptive field should change accordingly. To handlethis problem, we present a dense receptive field (DRF) moduleto capture rich local context information with dense receptivefields, as well as global context information. DRF utilizesthe multi-receptive-field (MRF) units connected densely topromote the multi-scale representation ability of features.Based on the proposed JAFF module and DRF module,we develop the joint attention-guided feature fusion network(JAFFNet) for saliency detection of surface defects. In sum-mary, the main contributions are as follows:1) We develop a joint attention-guided feature fusion net-work (JAFFNet) for saliency detection of surface defectsby introducing two plug-and-play modules, which canachieve end-to-end defect detection.2) We present a joint attention-guided feature fusion (JAFF)module to effectively fuse high-level and low-levelfeatures. It is able to select valuable low-level defectfeatures and suppress background interference duringfeature fusion via the learned joint channel-spatial at-tention map.3) We present a dense receptive field (DRF) module tocapture context information with larger and denser scaleranges. It exploits rich context information by denselyconnecting a series of multi-receptive-field units and canhandle defects with various scales.4) The experiments on three publicly available surface de-fect datasets, including SD-saliency-900, DAGM 2007,and Magnetic Tile, demonstrate that the proposedmethod not only achieves promising defect detectionperformance but also reaches a real-time detection speedof 66 FPS.II. R ELATED WORKSA. Traditional defect inspection methodsMost traditional surface defect inspection methods are basedon texture analysis, which can be broadly classified intofour categories: filter-based, statistic-based, model-based, andstructure-based approaches. Specifically, the filter-based meth-ods analyze texture features through filters, such as Fouriertransform, Gabor transform [1], and Wavelet transform. Thestatistic-based methods analyze texture features through sta-tistical distribution characteristics of the image, such as gray-level co-occurrence matrix (GLCM) [2], local binary pattern(LBP) [3]. The model-based methods describe texture featuresthrough statistics of model parameters, such as the randomfield model, and fractal model [4]. The structure-based ap-proaches analyze texture features through texture primitivesand spatial placement rules, such as [5]. And these methodsare most customized for specific types of defects, with poorreusability and generalization ability. In addition, these meth-ods cannot effectively deal with complicated defects.B. Deep-learning-based defect inspection methodsCompared with traditional surface defect inspection meth-ods, deep-learning-based defect inspection methods are ableto handle defects with weak characteristics and complexbackground, and show superiority in complex scenes. And webroadly divide these methods into two categories: region-leveland pixel-level defect inspection methods.1) Region-level inspection methods: These methods locatedefects by bounding boxes. To improve the defect detectionability of the model, He et al. [15] first integrate multi-levelfeatures into one feature and then feed it into the regionproposal network to generate high-quality defect proposals.Wei et al. [16] incorporate the attention-related visual gainIEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 3Fig. 2. Architecture of the proposed network. Our model consists of an encoder and a decoder, where we obtain multi-level features with channels 64, 128,256, 512, and 512 from five encoding stages E1 âˆ¼ E5, respectively. And D1 âˆ¼ D4 represent four decoding stages with each including a joint attention-guidedfeature fusion (JAFF) module and a convolution block. And the JAFF focuses on the fusion of high-level and low-level features. It incorporates a dual attentionmodule consisting of a channel attention branch (CAB) and a spatial attention branch (SAB) to generate the learned channel-spatial attention map that providesguidance for feature fusion. The dense receptive field (DRF) module after the encoder is used to capture dense context information. And the â€œDSâ€ and â€œrâ€denote depthwise separable convolution and rate of dilated convolution, respectively.mechanism into the Faster RCNN model to improve thediscrimination ability of small defects. However, these detec-tors obtain bounding boxes based on region proposals, withhigh accuracy but slow speed. Therefore, Cui et al. [17]design a fast and accurate detector called SDDNet, whichdetects small defects by passing fine-grained details of low-level features to all deep features. Su et al. [18] adopt anovel attention module (RCAG) to fuse multi-scale features,with the aim of emphasizing defect features and suppressingbackground noise. Different from [17] and [18], Tu et al. [19]achieve accurate defect detection by adopting CIoU loss andintroducing the Gaussian function to estimate the coordinatesof the prediction boxes.2) Pixel-level inspection methods: These methods can pro-vide more structural details of defects than region-level meth-ods, such as boundary, shape, and size. It is essential foraccurate defect detection to capture and integrate multiplecontext information effectively. To this end, Huang et al.[20] apply an atrous spatial pyramid pooling (ASPP) in theproposed lightweight defect segmentation network to capturemultiple context information. Zhang et al. [21] integrate mul-tiple context information through the pyramid pooling module(PPM) and attention module, with the aim of enhancing defectfeatures and filtering out noise. Li et al. [22] integrate multi-scale features from encoder blocks step-by-step, which se-quentially fuses two adjacent scale features and three adjacentscale features. In addition, the attention mechanism is alsooften used in defect segmentation to address those defectswith complex background. For example, Song et al. [23]incorporate the attention mechanism into the model to steerit to focus more on defect features. Zhou et al. [24] introducedense attention cues into the decoder to make it more defect-focused.Different from these existing methods, we propose a jointattention-guided feature fusion network for saliency detectionof surface defects. Specifically, we design two modules toimprove the defect detection performance of encoder-decoderarchitecture. One is called JAFF module, which is used ateach decoding stage to retain more defect features during thefusion of low-level and high-level features. The other is calledDRF module, which is embedded after the fifth encodingstage to capture dense context information and strengthen therepresentation ability of deep features. And the proposed twomodules greatly improve defect detection performance of thenetwork in complex scenes.C. Attention Mechanism in CNNsThe attention mechanism can selectively focus on importantinformation while ignoring less useful information, which isimportant for understanding complex scenes. Hu et al. [25]first propose channel attention and perform adaptive featureIEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 4recalibration by explicitly modeling global information. Dueto the limitation of channel attention, Woo et al. [26] proposethe convolutional block attention module (CBAM) whichapplies both channel-wise and spatial attention in sequential.CBAM not only introduces spatial attention but also introducesboth max-pooled and average-pooled features in the spatialaxis into channel attention. Park et al. [27] also design the";
    prompt = "è¯·æ€»ç»“ä¸‹é¢çš„æ–‡æ¡£ï¼Œè¾“å‡ºæ‘˜è¦å’Œå…³é”®è¯:å››ã€ä¸»è¦è´¢åŠ¡æ•°æ®åˆ†æž\nï¼ˆä¸€ï¼‰ä¼ä¸šå¿å€ºèƒ½åŠ›åˆ†æž\n1.çŸ­æœŸå¿å€ºèƒ½åŠ›åˆ†æž \nAã€æµåŠ¨æ¯”çŽ‡åˆ†æžï¼ˆæµåŠ¨æ¯”çŽ‡=æµåŠ¨èµ„äº§/æµåŠ¨è´Ÿå€º*100%ï¼‰ï¼šä¸­å›½å…¨èšå¾·2009å¹´æµåŠ¨æ¯”çŽ‡ä¸º104.5%ï¼Œ2008å¹´ä¸º135.4%ï¼Œã€‚æµåŠ¨æ¯”çŽ‡åŒæ¯”åŽ»å¹´æœ‰æ‰€ä¸‹é™ï¼Œè¯´æ˜Žä¼ä¸šçŸ­æœŸå¿å€ºèƒ½åŠ›å‡å¼±ã€‚ä»Žå…¬å¸2009å¹´çš„èµ„äº§è´Ÿå€ºè¡¨å¯ä»¥çœ‹å‡ºï¼Œå…¬å¸æµåŠ¨è´Ÿå€ºåŒæ¯”åŽ»å¹´æœ‰æ‰€ä¸Šå‡ï¼Œæ˜¯å¯¼è‡´æµåŠ¨æ¯”çŽ‡ä¸‹é™çš„é‡è¦åŽŸå› ã€‚\nBã€é€ŸåŠ¨æ¯”çŽ‡åˆ†æžï¼ˆé€ŸåŠ¨æ¯”çŽ‡=é€ŸåŠ¨èµ„äº§ï¼ˆæµåŠ¨èµ„äº§-å­˜è´§ï¼‰/æµåŠ¨è´Ÿå€º*100%ï¼‰ï¼š2009å¹´ä¼ä¸šçš„é€ŸåŠ¨æ¯”çŽ‡ä¸º77.86%ï¼Œ2008å¹´ä¸º120.41%ï¼Œ ä¼ä¸šè¯¥æŒ‡æ ‡ä¿æŒåœ¨1ä¸ºå¥½ï¼Œè¿‡å¤§è¿‡å°éƒ½æœ‰è´Ÿé¢çš„å½±å“ã€‚ä¸­å›½å…¨èšå¾·2009å¹´é€ŸåŠ¨æ¯”çŽ‡ä¸º77.86%ä½ŽäºŽ1ï¼Œè¶³ä»¥è¡¨æ˜Žä¼ä¸šçš„çŸ­æœŸå¿å€ºèƒ½åŠ›ç•¥ä½Žã€‚åœ¨ä¿è¯ä¼ä¸šèµ„æºå¾—åˆ°å……åˆ†åˆ©ç”¨çš„å‰æä¸‹ï¼Œå»ºè®®å¢žåŠ æŒæœ‰æµåŠ¨èµ„äº§ï¼Œå¢žå¼ºä¼ä¸šçŸ­æœŸå¿å€ºèƒ½åŠ›ã€‚\n2.ä¼ä¸šé•¿æœŸå¿å€ºèƒ½åŠ›åˆ†æž\nAã€èµ„äº§è´Ÿå€ºçŽ‡åˆ†æžï¼ˆèµ„äº§è´Ÿå€ºçŽ‡=è´Ÿå€ºæ€»é¢/èµ„äº§æ€»é¢*100%ï¼‰ï¼š2008å¹´ï¼Œä¸­å›½å…¨èšå¾·çš„èµ„äº§è´Ÿå€ºçŽ‡ä¸º26.97%ï¼Œ2009å¹´ä¸º32.56%ï¼Œä»Žèµ„äº§è´Ÿå€ºè¡¨å¯ä»¥çœ‹å‡ºï¼Œåœ¨å›½é™…é‡‘èžå±æœºçš„å½±å“ä¸‹ï¼Œä¼ä¸šè´Ÿå€ºå¢žåŠ å¯¼è‡´èµ„äº§è´Ÿå€ºçŽ‡æœ‰æ‰€æé«˜ï¼Œç»è¥é£Žé™©å¢žåŠ ã€‚å›½å†…å…¬è®¤æ­¤æŒ‡æ ‡ä¸è¶…è¿‡50%è¾ƒå¥½ï¼Œä¼ä¸šçš„èµ„äº§è´Ÿå€ºçŽ‡æé«˜ï¼Œä¼ä¸šæ€»çš„å¿å€ºèƒ½åŠ›é™ä½Žã€‚\nBã€è´Ÿå€ºè‚¡æƒæ¯”çŽ‡ï¼šè´Ÿå€ºè‚¡æƒæ¯”çŽ‡æ˜¯ä»Žè‚¡ä¸œæƒç›Šå¯¹é•¿æœŸè´Ÿå€ºçš„ä¿éšœç¨‹åº¦æ¥è¯„ä»·ä¼ä¸šçš„é•¿æœŸå¿å€ºèƒ½åŠ›çš„ã€‚2009å¹´ï¼Œä¸­å›½å…¨èšå¾·çš„è´Ÿå€ºè‚¡æƒæ¯”çŽ‡ä¸‹é™æ˜Žæ˜¾ï¼Œä¼ä¸šæ‰€æœ‰è€…æƒç›Šå¯¹å€ºæƒçš„ä¿éšœç¨‹åº¦è¾ƒé«˜ï¼Œä¼ä¸šè´¢åŠ¡é£Žé™©è¾ƒå°ã€‚\nï¼ˆäºŒï¼‰èµ„æœ¬çŠ¶å†µåˆ†æž\n1ã€èµ„æœ¬ä¿å€¼å¢žå€¼çŽ‡ï¼ˆèµ„æœ¬ä¿å€¼å¢žå€¼çŽ‡=æ‰£é™¤å®¢è§‚å› ç´ åŽçš„å¹´æœ«æ‰€æœ‰è€…æƒç›Š/å¹´åˆæ‰€æœ‰è€…æƒç›Š*100%ï¼‰ï¼šå…¨èšå¾·2009å¹´èµ„æœ¬ä¿å€¼å¢žåŠ¿çŽ‡ä¸º107%ã€‚è¯¥æ•°æ®è¡¨æ˜Žä¸­å›½å…¨èšå¾·çš„èµ„æœ¬ä¿å…¨æƒ…å†µå®Œå¥½ï¼Œä¼ä¸šå‘å±•æ½œåŠ›è¿˜å¾ˆå¤§ï¼Œå€ºæƒäººåˆ©ç›Šä¿éšœç¨‹åº¦æ¯”è¾ƒä¹è§‚ã€‚\n2ã€èµ„æœ¬ç§¯ç´¯çŽ‡ï¼ˆèµ„æœ¬ç§¯ç´¯çŽ‡=æœ¬å¹´æ‰€æœ‰è€…æƒç›Šå¢žé•¿é¢/å¹´åˆæ‰€æœ‰è€…æƒç›Š*100%ï¼‰ï¼šå…¨èšå¾·2009å¹´èµ„æœ¬ç§¯ç´¯çŽ‡ä¸º7%ï¼Œæ‰€æœ‰è€…æƒç›Šå¢žé•¿è¾ƒåŒè¡Œä¸šä¼ä¸šç›¸å¯¹è¾ƒå¿«ï¼Œæœ‰è‰¯å¥½çš„èµ„æœ¬ç§¯ç´¯èƒ½åŠ›ï¼Œèµ„æœ¬ä¿å…¨æƒ…å†µè‰¯å¥½ï¼ŒæŒç»­å‘å±•èƒ½åŠ›è¾ƒå¤§ã€‚\nï¼ˆä¸‰ï¼‰ä¼ä¸šè¥è¿èƒ½åŠ›åˆ†æž\n1ã€ åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡åŠå‘¨è½¬å¤©æ•°ï¼šæ®æ•°æ®ç»Ÿè®¡ï¼Œä¸­å›½é¤é¥®åˆ¶é€ ä¼ä¸šçš„å¹³å‡åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡ä¸º2.12ï¼Œåº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°ä¸º104å¤©ã€‚ä¸­å›½å…¨èšå¾·çš„åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡å’Œåº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°è¿™ä¸¤ä¸ªæŒ‡æ ‡éƒ½ä¼˜äºŽè¡Œä¸šå¹³å‡æ°´å¹³ï¼Œä¸”åœ¨2009å¹´é—´ï¼Œä¼ä¸šåº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡ä¸æ–­ä¸Šå‡ï¼Œåº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°ä¸æ–­ä¸‹é™ï¼Œè¯´æ˜Žæ”¶å¸é€Ÿåº¦å¿«ï¼Œå¹³å‡æ”¶è´¦æœŸçŸ­ï¼Œåå¸æŸå¤±å°‘ï¼Œèµ„äº§æµåŠ¨å¿«ï¼Œå¿å€ºèƒ½åŠ›å¼ºã€‚\n2ã€å­˜è´§å‘¨è½¬å¤©æ•°åŠå­˜è´§å‘¨è½¬çŽ‡ï¼šé¤é¥®åˆ¶é€ ä¸šçš„å¹³å‡å­˜è´§å‘¨è½¬çŽ‡ä¸º3.96ï¼Œå¹³å‡å­˜è´§å‘¨è½¬å¤©æ•°ä¸º90.91å¤©ã€‚ç›¸å¯¹äºŽè¡Œä¸šå¹³å‡æ°´å¹³ï¼Œä¸­å›½å…¨èšå¾·çš„å­˜è´§å‘¨è½¬çŽ‡ç¨ä½Žï¼Œå­˜è´§å‘¨è½¬å¤©æ•°ç•¥é«˜ã€‚çºµå‘æ¯”è¾ƒï¼Œä¼ä¸šçš„å­˜è´§å‘¨è½¬çŽ‡ä»Ž2008å¹´ä»¥æ¥ä¸€ç›´ä¸‹é™ï¼Œè¯´æ˜Žä¼ä¸šå­˜è´§ç®¡ç†æ°´å¹³ä¸‹é™ï¼Œé”€å”®èƒ½åŠ›å˜å¼±ã€‚ä¸»è¦åŽŸå› æ˜¯æ”¶é‡‘èžå±æœºå½±å“ï¼Œå¯¼è‡´ä¼ä¸šåº“å­˜å¢žåŠ ï¼Œäº§å“é”€å”®å›°éš¾ã€‚ä½œä¸ºè¡Œä¸šå†…é¢†å…ˆä¼ä¸šï¼Œä¸­å›½å…¨èšå¾·åº”åŠ å¼ºå­˜è´§ç®¡ç†ï¼Œé‡‡å–ç§¯æžçš„é”€å”®ç­–ç•¥ï¼Œå‡å°‘å­˜è´§è¥è¿èµ„é‡‘å ç”¨é‡ã€‚\näº”ã€ä¼šè®¡æŠ¥è¡¨ç»“æž„åˆ†æž\nï¼ˆä¸€ï¼‰èµ„äº§è´Ÿå€ºè¡¨ç»“æž„åˆ†æž\n1ã€èµ„äº§æ–¹é¢ï¼šæ€»ä½“çœ‹2009å¹´ä¸­å›½å…¨èšå¾·èµ„äº§æœ‰æ‰€å¢žé•¿ã€‚å…·ä½“å˜åŠ¨æƒ…å†µå¦‚ä¸‹å„è¡¨æ‰€ç¤ºï¼š\nå¦‚å›¾ç¤ºï¼Œä¸¤å¹´ç›¸æ¯”è¾ƒä¼ä¸šçš„æµåŠ¨èµ„äº§æ€»é¢æ— è¾ƒå¤§å˜åŠ¨ï¼Œä½†æ˜¯å­˜è´§æœ‰è¾ƒå¤§å¹…åº¦çš„å¢žåŠ ï¼Œè€Œè´§å¸èµ„é‡‘åˆ™æœ‰è¾ƒå¤§å¹…åº¦çš„ä¸‹é™ï¼Œè¿™å¯¼è‡´æ€»é¢çš„å˜åŠ¨å¹…åº¦ä¸å¤§ã€‚\n2009å¹´ï¼Œå…¬å¸æ·±åŒ–æ”¹é©ï¼ŒåŠ å¤§è¥é”€åŠ›åº¦ï¼Œåˆ†å…¬å¸é¡ºåˆ©å®žçŽ°ä»Žç²—æ”¾åž‹åˆ°é›†çº¦åž‹ã€ä»Žç”Ÿäº§åž‹åˆ°ç»è¥åž‹çš„è½¬åŒ–ï¼Œä¸­å›½å…¨èšå¾·çš„å¸‚åœºæ”»å‡»åŠ›å¿«é€Ÿæå‡ã€‚å¸‚åœºä»½é¢çš„æ‰©å¤§å¿…ç„¶è¦æ±‚æä¾›æ›´å¤šåœ°äº§å“ï¼Œå› è€Œä¼ä¸šé€‚å½“çš„å¢žåŠ å­˜è´§æœ‰åˆ©äºŽä¼ä¸šçš„è¿è¥ï¼Œå› è€Œä¼ä¸šçš„è´§å¸èµ„é‡‘å¿…ç„¶è½¬åŒ–ä¸ºå­˜è´§çš„å½¢å¼ã€‚å¦ä¸€æ–¹é¢ï¼Œç”±äºŽå—åˆ°ç»æµŽå±æœºçš„å†²å‡»ï¼Œä¼ä¸šå®žé™…é”€å”®é‡å¯èƒ½ä½ŽäºŽé¢„æœŸé”€é‡ï¼Œå¯¼è‡´å­˜è´§ç§¯åŽ‹ï¼Œè¿™ä¹Ÿæ˜¯å¯¼è‡´å­˜è´§å¢žåŠ çš„ä¸€ä¸ªé‡è¦åŽŸå› ã€‚\n2ã€è´Ÿå€ºæ–¹é¢ï¼š\nä¸­å›½å…¨èšå¾·çš„èµ„äº§è´Ÿå€ºçŽ‡åœ¨è¿‘å‡ å¹´é—´æœ‰æ‰€ä¸Šå‡ã€‚ä¸»è¦åŽŸå› éƒ½æ˜¯åº”ä»˜è´¦æ¬¾å¢žåŠ ã€åº”ä»˜ç¥¨æ®å¢žåŠ ã€é¢„æ”¶è´¦æ¬¾å¢žåŠ ä»¥åŠå…¶ä»–åº”ä»˜æ¬¾å¢žåŠ ã€‚ä»Žèµ„äº§è´Ÿå€ºè¡¨å¯ä»¥çœ‹å‡ºï¼Œå…¬å¸è´Ÿå€ºä¸­æµåŠ¨è´Ÿå€ºå ç»å¤§å¤šæ•°ï¼Œå…¬å¸å¾ˆå¥½çš„è¿ç”¨äº†çŸ­æœŸè´Ÿå€ºç­¹èµ„é€Ÿåº¦å¿«ã€å¯Œæœ‰å¼¹æ€§ã€æˆæœ¬ä½Žçš„ä¼˜ç‚¹ï¼Œä¸”å…¬å¸å¯¹è´Ÿå€ºè§„æ¨¡è¿›è¡Œæ€»ä½“æŽ§åˆ¶ï¼Œå…¬å¸çš„è´¢åŠ¡é£Žé™©è¾ƒå°ã€‚\nå…­ã€å…¬å¸ç»è¥æƒ…å†µè¯„è¿°\nä»Žä»¥ä¸Šåˆ†æžå¯ä»¥çœ‹å‡ºï¼Œä¸­å›½å…¨èšå¾·çš„å„é¡¹æŒ‡æ ‡åŸºæœ¬ä¸Šéƒ½ä¼˜äºŽè¡Œä¸šå‡å€¼ï¼Œè¯´æ˜Žå…¬å¸çš„ç»è¥çŠ¶å†µè‰¯å¥½ã€‚ä¸­å›½å…¨èšå¾·æ˜¯ä¸­åŽé¤é¥®çš„ç‘°å®ï¼Œåœ¨è¿‡åŽ»çš„äº”å¹´ï¼Œä¸­å›½å…¨èšå¾·æ˜¯ä¸­å›½æœ€ä¼˜ç§€çš„é¤é¥®ä¼ä¸šï¼Œå…¶æ ¸å¿ƒç«žäº‰åŠ›åœ¨äºŽç‹¬ç‰¹çš„èµ„æºä¼˜åŠ¿ã€å‡ºè‰²çš„ç®¡ç†èƒ½åŠ›ä»¥åŠè¶…å‰çš„æˆ˜ç•¥çœ¼å…‰ã€‚å…¬å¸è¥è¿èƒ½åŠ›å’Œç®¡ç†æ•ˆçŽ‡å±…äºŽåŒè¡Œä¸šé¢†å…ˆæ°´å¹³ï¼Œä½¿ä¸­å›½å…¨èšå¾·ä»Žä¸€ä¸ªå…¨å›½æ€§çš„ä¼ä¸šæˆé•¿ä¸ºä¸€ä¸ªå›½é™…æ€§çš„ä¼ä¸šï¼Œä»Žä¸€ä¸ªè¡Œä¸šçš„æŒ‘æˆ˜è€…æˆé•¿ä¸ºè¡Œä¸šé¢†è·‘è€…ã€‚è¿‘ä¸¤å¹´ï¼Œå…¬å¸è¿›è¡Œäº†å¹¶è´­é‡ç»„ï¼Œæ‰©å¤§äº†å…¬å¸è§„æ¨¡ï¼Œç ”å‘èƒ½åŠ›åŠé”€å”®æ¸ é“å®žçŽ°äº†å…±äº«ï¼Œé™ä½Žäº†å…¬å¸çš„æˆæœ¬ï¼Œæœ‰æ•ˆçš„å¼ºåŒ–äº†å…¬å¸çš„ç«žäº‰åŠ›ã€‚å…¬å¸é¢„è®¡2009å¹´é›†å›¢é”€å”®æ”¶å…¥èƒ½è¾¾åˆ°4.5äº¿å…ƒã€‚\nä¸ƒã€å…¬å¸å­˜åœ¨é—®é¢˜åŠæ”¹è¿›å»ºè®®\nä¸­å›½å…¨èšå¾·æ˜¯è¡Œä¸šå†…é¢†å…ˆä¼ä¸šï¼Œå…¬å¸ç®¡ç†æ°´å¹³é«˜ï¼Œå…¬å¸é”€å”®æ”¶å…¥å’Œåˆ©æ¶¦éƒ½é¢†å…ˆå…¶ä»–ä¼ä¸šï¼Œä½†ç»“åˆå‰é¢çš„åˆ†æžæ¥çœ‹ï¼Œå…¬å¸ä»ç„¶å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ã€‚ä¸€æ˜¯å…¬å¸çš„å­˜è´§å‘¨è½¬çŽ‡è¾ƒä½Žï¼Œå­˜è´§å‘¨è½¬å¤©æ•°é•¿ã€‚";
    
    //std::string prompt1 = "è¯·æ€»ç»“ä¸‹é¢çš„æ–‡æ¡£ï¼Œè¾“å‡ºæ‘˜è¦å’Œå…³é”®è¯:å››ã€ä¸»è¦è´¢åŠ¡æ•°æ®åˆ†æž\nï¼ˆä¸€ï¼‰ä¼ä¸šå¿å€ºèƒ½åŠ›åˆ†æž\n1.çŸ­æœŸå¿å€ºèƒ½åŠ›åˆ†æž \nAã€æµåŠ¨æ¯”çŽ‡åˆ†æžï¼ˆæµåŠ¨æ¯”çŽ‡=æµåŠ¨èµ„äº§/æµåŠ¨è´Ÿå€º*100%ï¼‰ï¼šä¸­å›½å…¨èšå¾·2009å¹´æµåŠ¨æ¯”çŽ‡ä¸º104.5%ï¼Œ2008å¹´ä¸º135.4%ï¼Œã€‚æµåŠ¨æ¯”çŽ‡åŒæ¯”åŽ»å¹´æœ‰æ‰€ä¸‹é™ï¼Œè¯´æ˜Žä¼ä¸šçŸ­æœŸå¿å€ºèƒ½åŠ›å‡å¼±ã€‚ä»Žå…¬å¸2009å¹´çš„èµ„äº§è´Ÿå€ºè¡¨å¯ä»¥çœ‹å‡ºï¼Œå…¬å¸æµåŠ¨è´Ÿå€ºåŒæ¯”åŽ»å¹´æœ‰æ‰€ä¸Šå‡ï¼Œæ˜¯å¯¼è‡´æµåŠ¨æ¯”çŽ‡ä¸‹é™çš„é‡è¦åŽŸå› ã€‚\nBã€é€ŸåŠ¨æ¯”çŽ‡åˆ†æžï¼ˆé€ŸåŠ¨æ¯”çŽ‡=é€ŸåŠ¨èµ„äº§ï¼ˆæµåŠ¨èµ„äº§-å­˜è´§ï¼‰/æµåŠ¨è´Ÿå€º*100%ï¼‰ï¼š2009å¹´ä¼ä¸šçš„é€ŸåŠ¨æ¯”çŽ‡ä¸º77.86%ï¼Œ2008å¹´ä¸º120.41%ï¼Œ ä¼ä¸šè¯¥æŒ‡æ ‡ä¿æŒåœ¨1ä¸ºå¥½ï¼Œè¿‡å¤§è¿‡å°éƒ½æœ‰è´Ÿé¢çš„å½±å“ã€‚ä¸­å›½å…¨èšå¾·2009å¹´é€ŸåŠ¨æ¯”çŽ‡ä¸º77.86%ä½ŽäºŽ1ï¼Œè¶³ä»¥è¡¨æ˜Žä¼ä¸šçš„çŸ­æœŸå¿å€ºèƒ½åŠ›ç•¥ä½Žã€‚åœ¨ä¿è¯ä¼ä¸šèµ„æºå¾—åˆ°å……åˆ†åˆ©ç”¨çš„å‰æä¸‹ï¼Œå»ºè®®å¢žåŠ æŒæœ‰æµåŠ¨èµ„äº§ï¼Œå¢žå¼ºä¼ä¸šçŸ­æœŸå¿å€ºèƒ½åŠ›ã€‚\n2.ä¼ä¸šé•¿æœŸå¿å€ºèƒ½åŠ›åˆ†æž\nAã€èµ„äº§è´Ÿå€ºçŽ‡åˆ†æžï¼ˆèµ„äº§è´Ÿå€ºçŽ‡=è´Ÿå€ºæ€»é¢/èµ„äº§æ€»é¢*100%ï¼‰ï¼š2008å¹´ï¼Œä¸­å›½å…¨èšå¾·çš„èµ„äº§è´Ÿå€ºçŽ‡ä¸º26.97%ï¼Œ2009å¹´ä¸º32.56%ï¼Œä»Žèµ„äº§è´Ÿå€ºè¡¨å¯ä»¥çœ‹å‡ºï¼Œåœ¨å›½é™…é‡‘èžå±æœºçš„å½±å“ä¸‹ï¼Œä¼ä¸šè´Ÿå€ºå¢žåŠ å¯¼è‡´èµ„äº§è´Ÿå€ºçŽ‡æœ‰æ‰€æé«˜ï¼Œç»è¥é£Žé™©å¢žåŠ ã€‚å›½å†…å…¬è®¤æ­¤æŒ‡æ ‡ä¸è¶…è¿‡50%è¾ƒå¥½ï¼Œä¼ä¸šçš„èµ„äº§è´Ÿå€ºçŽ‡æé«˜ï¼Œä¼ä¸šæ€»çš„å¿å€ºèƒ½åŠ›é™ä½Žã€‚\nBã€è´Ÿå€ºè‚¡æƒæ¯”çŽ‡ï¼šè´Ÿå€ºè‚¡æƒæ¯”çŽ‡æ˜¯ä»Žè‚¡ä¸œæƒç›Šå¯¹é•¿æœŸè´Ÿå€ºçš„ä¿éšœç¨‹åº¦æ¥è¯„ä»·ä¼ä¸šçš„é•¿æœŸå¿å€ºèƒ½åŠ›çš„ã€‚2009å¹´ï¼Œä¸­å›½å…¨èšå¾·çš„è´Ÿå€ºè‚¡æƒæ¯”çŽ‡ä¸‹é™æ˜Žæ˜¾ï¼Œä¼ä¸šæ‰€æœ‰è€…æƒç›Šå¯¹å€ºæƒçš„ä¿éšœç¨‹åº¦è¾ƒé«˜ï¼Œä¼ä¸šè´¢åŠ¡é£Žé™©è¾ƒå°ã€‚\nï¼ˆäºŒï¼‰èµ„æœ¬çŠ¶å†µåˆ†æž\n1ã€èµ„æœ¬ä¿å€¼å¢žå€¼çŽ‡ï¼ˆèµ„æœ¬ä¿å€¼å¢žå€¼çŽ‡=æ‰£é™¤å®¢è§‚å› ç´ åŽçš„å¹´æœ«æ‰€æœ‰è€…æƒç›Š/å¹´åˆæ‰€æœ‰è€…æƒç›Š*100%ï¼‰ï¼šå…¨èšå¾·2009å¹´èµ„æœ¬ä¿å€¼å¢žåŠ¿çŽ‡ä¸º107%ã€‚è¯¥æ•°æ®è¡¨æ˜Žä¸­å›½å…¨èšå¾·çš„èµ„æœ¬ä¿å…¨æƒ…å†µå®Œå¥½ï¼Œä¼ä¸šå‘å±•æ½œåŠ›è¿˜å¾ˆå¤§ï¼Œå€ºæƒäººåˆ©ç›Šä¿éšœç¨‹åº¦æ¯”è¾ƒä¹è§‚ã€‚\n2ã€èµ„æœ¬ç§¯ç´¯çŽ‡ï¼ˆèµ„æœ¬ç§¯ç´¯çŽ‡=æœ¬å¹´æ‰€æœ‰è€…æƒç›Šå¢žé•¿é¢/å¹´åˆæ‰€æœ‰è€…æƒç›Š*100%ï¼‰ï¼šå…¨èšå¾·2009å¹´èµ„æœ¬ç§¯ç´¯çŽ‡ä¸º7%ï¼Œæ‰€æœ‰è€…æƒç›Šå¢žé•¿è¾ƒåŒè¡Œä¸šä¼ä¸šç›¸å¯¹è¾ƒå¿«ï¼Œæœ‰è‰¯å¥½çš„èµ„æœ¬ç§¯ç´¯èƒ½åŠ›ï¼Œèµ„æœ¬ä¿å…¨æƒ…å†µè‰¯å¥½ï¼ŒæŒç»­å‘å±•èƒ½åŠ›è¾ƒå¤§ã€‚\nï¼ˆä¸‰ï¼‰ä¼ä¸šè¥è¿èƒ½åŠ›åˆ†æž\n1ã€ åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡åŠå‘¨è½¬å¤©æ•°ï¼šæ®æ•°æ®ç»Ÿè®¡ï¼Œä¸­å›½é¤é¥®åˆ¶é€ ä¼ä¸šçš„å¹³å‡åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡ä¸º2.12ï¼Œåº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°ä¸º104å¤©ã€‚ä¸­å›½å…¨èšå¾·çš„åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡å’Œåº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°è¿™ä¸¤ä¸ªæŒ‡æ ‡éƒ½ä¼˜äºŽè¡Œä¸šå¹³å‡æ°´å¹³ï¼Œä¸”åœ¨2009å¹´é—´ï¼Œä¼ä¸šåº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡ä¸æ–­ä¸Šå‡ï¼Œåº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°ä¸æ–­ä¸‹é™ï¼Œè¯´æ˜Žæ”¶å¸é€Ÿåº¦å¿«ï¼Œå¹³å‡æ”¶è´¦æœŸçŸ­ï¼Œåå¸æŸå¤±å°‘ï¼Œèµ„äº§æµåŠ¨å¿«ï¼Œå¿å€ºèƒ½åŠ›å¼ºã€‚\n2ã€å­˜è´§å‘¨è½¬å¤©æ•°åŠå­˜è´§å‘¨è½¬çŽ‡ï¼šé¤é¥®åˆ¶é€ ä¸šçš„å¹³å‡å­˜è´§å‘¨è½¬çŽ‡ä¸º3.96ï¼Œå¹³å‡å­˜è´§å‘¨è½¬å¤©æ•°ä¸º90.91å¤©ã€‚ç›¸å¯¹äºŽè¡Œä¸šå¹³å‡æ°´å¹³ï¼Œä¸­å›½å…¨èšå¾·çš„å­˜è´§å‘¨è½¬çŽ‡ç¨ä½Žï¼Œå­˜è´§å‘¨è½¬å¤©æ•°ç•¥é«˜ã€‚çºµå‘æ¯”è¾ƒï¼Œä¼ä¸šçš„å­˜è´§å‘¨è½¬çŽ‡ä»Ž2008å¹´ä»¥æ¥ä¸€ç›´ä¸‹é™ï¼Œè¯´æ˜Žä¼ä¸šå­˜è´§ç®¡ç†æ°´å¹³ä¸‹é™ï¼Œé”€å”®èƒ½åŠ›å˜å¼±ã€‚ä¸»è¦åŽŸå› æ˜¯æ”¶é‡‘èžå±æœºå½±å“ï¼Œå¯¼è‡´ä¼ä¸šåº“å­˜å¢žåŠ ï¼Œäº§å“é”€å”®å›°éš¾ã€‚ä½œä¸ºè¡Œä¸šå†…é¢†å…ˆä¼ä¸šï¼Œä¸­å›½å…¨èšå¾·åº”åŠ å¼ºå­˜è´§ç®¡ç†ï¼Œé‡‡å–ç§¯æžçš„é”€å”®ç­–ç•¥ï¼Œå‡å°‘å­˜è´§è¥è¿èµ„é‡‘å ç”¨é‡ã€‚\näº”ã€ä¼šè®¡æŠ¥è¡¨ç»“æž„åˆ†æž\nï¼ˆä¸€ï¼‰èµ„äº§è´Ÿå€ºè¡¨ç»“æž„åˆ†æž\n1ã€èµ„äº§æ–¹é¢ï¼šæ€»ä½“çœ‹2009å¹´ä¸­å›½å…¨èšå¾·èµ„äº§æœ‰æ‰€å¢žé•¿ã€‚å…·ä½“å˜åŠ¨æƒ…å†µå¦‚ä¸‹å„è¡¨æ‰€ç¤ºï¼š\nå¦‚å›¾ç¤ºï¼Œä¸¤å¹´ç›¸æ¯”è¾ƒä¼ä¸šçš„æµåŠ¨èµ„äº§æ€»é¢æ— è¾ƒå¤§å˜åŠ¨ï¼Œä½†æ˜¯å­˜è´§æœ‰è¾ƒå¤§å¹…åº¦çš„å¢žåŠ ï¼Œè€Œè´§å¸èµ„é‡‘åˆ™æœ‰è¾ƒå¤§å¹…åº¦çš„ä¸‹é™ï¼Œè¿™å¯¼è‡´æ€»é¢çš„å˜åŠ¨å¹…åº¦ä¸å¤§ã€‚\n2009å¹´ï¼Œå…¬å¸æ·±åŒ–æ”¹é©ï¼ŒåŠ å¤§è¥é”€åŠ›åº¦ï¼Œåˆ†å…¬å¸é¡ºåˆ©å®žçŽ°ä»Žç²—æ”¾åž‹åˆ°é›†çº¦åž‹ã€ä»Žç”Ÿäº§åž‹åˆ°ç»è¥åž‹çš„è½¬åŒ–ï¼Œä¸­å›½å…¨èšå¾·çš„å¸‚åœºæ”»å‡»åŠ›å¿«é€Ÿæå‡ã€‚å¸‚åœºä»½é¢çš„æ‰©å¤§å¿…ç„¶è¦æ±‚æä¾›æ›´å¤šåœ°äº§å“ï¼Œå› è€Œä¼ä¸šé€‚å½“çš„å¢žåŠ å­˜è´§æœ‰åˆ©äºŽä¼ä¸šçš„è¿è¥ï¼Œå› è€Œä¼ä¸šçš„è´§å¸èµ„é‡‘å¿…ç„¶è½¬åŒ–ä¸ºå­˜è´§çš„å½¢å¼ã€‚å¦ä¸€æ–¹é¢ï¼Œç”±äºŽå—åˆ°ç»æµŽå±æœºçš„å†²å‡»ï¼Œä¼ä¸šå®žé™…é”€å”®é‡å¯èƒ½ä½ŽäºŽé¢„æœŸé”€é‡ï¼Œå¯¼è‡´å­˜è´§ç§¯åŽ‹ï¼Œè¿™ä¹Ÿæ˜¯å¯¼è‡´å­˜è´§å¢žåŠ çš„ä¸€ä¸ªé‡è¦åŽŸå› ã€‚\n2ã€è´Ÿå€ºæ–¹é¢ï¼š\nä¸­å›½å…¨èšå¾·çš„èµ„äº§è´Ÿå€ºçŽ‡åœ¨è¿‘å‡ å¹´é—´æœ‰æ‰€ä¸Šå‡ã€‚ä¸»è¦åŽŸå› éƒ½æ˜¯åº”ä»˜è´¦æ¬¾å¢žåŠ ã€åº”ä»˜ç¥¨æ®å¢žåŠ ã€é¢„æ”¶è´¦æ¬¾å¢žåŠ ä»¥åŠå…¶ä»–åº”ä»˜æ¬¾å¢žåŠ ã€‚ä»Žèµ„äº§è´Ÿå€ºè¡¨å¯ä»¥çœ‹å‡ºï¼Œå…¬å¸è´Ÿå€ºä¸­æµåŠ¨è´Ÿå€ºå ç»å¤§å¤šæ•°ï¼Œå…¬å¸å¾ˆå¥½çš„è¿ç”¨äº†çŸ­æœŸè´Ÿå€ºç­¹èµ„é€Ÿåº¦å¿«ã€å¯Œæœ‰å¼¹æ€§ã€æˆæœ¬ä½Žçš„ä¼˜ç‚¹ï¼Œä¸”å…¬å¸å¯¹è´Ÿå€ºè§„æ¨¡è¿›è¡Œæ€»ä½“æŽ§åˆ¶ï¼Œå…¬å¸çš„è´¢åŠ¡é£Žé™©è¾ƒå°ã€‚\nå…­ã€å…¬å¸ç»è¥æƒ…å†µè¯„è¿°\nä»Žä»¥ä¸Šåˆ†æžå¯ä»¥çœ‹å‡ºï¼Œä¸­å›½å…¨èšå¾·çš„å„é¡¹æŒ‡æ ‡åŸºæœ¬ä¸Šéƒ½ä¼˜äºŽè¡Œä¸šå‡å€¼ï¼Œè¯´æ˜Žå…¬å¸çš„ç»è¥çŠ¶å†µè‰¯å¥½ã€‚ä¸­å›½å…¨èšå¾·æ˜¯ä¸­åŽé¤é¥®çš„ç‘°å®ï¼Œåœ¨è¿‡åŽ»çš„äº”å¹´ï¼Œä¸­å›½å…¨èšå¾·æ˜¯ä¸­å›½æœ€ä¼˜ç§€çš„é¤é¥®ä¼ä¸šï¼Œå…¶æ ¸å¿ƒç«žäº‰åŠ›åœ¨äºŽç‹¬ç‰¹çš„èµ„æºä¼˜åŠ¿ã€å‡ºè‰²çš„ç®¡ç†èƒ½åŠ›ä»¥åŠè¶…å‰çš„æˆ˜ç•¥çœ¼å…‰ã€‚å…¬å¸è¥è¿èƒ½åŠ›å’Œç®¡ç†æ•ˆçŽ‡å±…äºŽåŒè¡Œä¸šé¢†å…ˆæ°´å¹³ï¼Œä½¿ä¸­å›½å…¨èšå¾·ä»Žä¸€ä¸ªå…¨å›½æ€§çš„ä¼ä¸šæˆé•¿ä¸ºä¸€ä¸ªå›½é™…æ€§çš„ä¼ä¸šï¼Œä»Žä¸€ä¸ªè¡Œä¸šçš„æŒ‘æˆ˜è€…æˆé•¿ä¸ºè¡Œä¸šé¢†è·‘è€…ã€‚è¿‘ä¸¤å¹´ï¼Œå…¬å¸è¿›è¡Œäº†å¹¶è´­é‡ç»„ï¼Œæ‰©å¤§äº†å…¬å¸è§„æ¨¡ï¼Œç ”å‘èƒ½åŠ›åŠé”€å”®æ¸ é“å®žçŽ°äº†å…±äº«ï¼Œé™ä½Žäº†å…¬å¸çš„æˆæœ¬ï¼Œæœ‰æ•ˆçš„å¼ºåŒ–äº†å…¬å¸çš„ç«žäº‰åŠ›ã€‚å…¬å¸é¢„è®¡2009å¹´é›†å›¢é”€å”®æ”¶å…¥èƒ½è¾¾åˆ°4.5äº¿å…ƒã€‚\nä¸ƒã€å…¬å¸å­˜åœ¨é—®é¢˜åŠæ”¹è¿›å»ºè®®\nä¸­å›½å…¨èšå¾·æ˜¯è¡Œä¸šå†…é¢†å…ˆä¼ä¸šï¼Œå…¬å¸ç®¡ç†æ°´å¹³é«˜ï¼Œå…¬å¸é”€å”®æ”¶å…¥å’Œåˆ©æ¶¦éƒ½é¢†å…ˆå…¶ä»–ä¼ä¸šï¼Œä½†ç»“åˆå‰é¢çš„åˆ†æžæ¥çœ‹ï¼Œå…¬å¸ä»ç„¶å­˜åœ¨ä¸¤ä¸ªé—®é¢˜ã€‚ä¸€æ˜¯å…¬å¸çš„å­˜è´§å‘¨è½¬çŽ‡è¾ƒä½Žï¼Œå­˜è´§å‘¨è½¬å¤©æ•°é•¿ã€‚";
    std::string prompt1 = "è¯·æ€»ç»“ä¸‹é¢çš„æ–‡æ¡£ï¼Œè¾“å‡ºæ‘˜è¦å’Œå…³é”®è¯:IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 1Joint Attention-Guided Feature Fusion Network forSaliency Detection of Surface DefectsXiaoheng Jiang, Feng Yan, Yang Lu, Ke Wang, Shuai GuoTianzhu Zhang, Yanwei Pang, Senior Member, IEEE, Jianwei Niu, Senior Member, IEEE, and Mingliang XuAbstractâ€”Surface defect inspection plays an important role inthe process of industrial manufacture and production. ThoughConvolutional Neural Network (CNN) based defect inspectionmethods have made huge leaps, they still confront a lot ofchallenges such as defect scale variation, complex background,low contrast, and so on. To address these issues, we proposea joint attention-guided feature fusion network (JAFFNet) forsaliency detection of surface defects based on the encoder-decodernetwork. JAFFNet mainly incorporates a joint attention-guidedfeature fusion (JAFF) module into decoding stages to adaptivelyfuse low-level and high-level features. The JAFF module learns toemphasize defect features and suppress background noise duringfeature fusion, which is beneficial for detecting low-contrastdefects. In addition, JAFFNet introduces a dense receptive field(DRF) module following the encoder to capture features with richcontext information, which helps detect defects of different scales.The JAFF module mainly utilizes a learned joint channel-spatialattention map provided by high-level semantic features to guidefeature fusion. The attention map makes the model pay moreattention to defect features. The DRF module utilizes a sequenceof multi-receptive-field (MRF) units with each taking as inputsall the preceding MRF feature maps and the original input. Theobtained DRF features capture rich context information with alarge range of receptive fields. Extensive experiments conductedon SD-saliency-900, Magnetic tile, and DAGM 2007 indicate thatour method achieves promising performance in comparison withother state-of-the-art methods. Meanwhile, our method reachesa real-time defect detection speed of 66 FPS.Index Termsâ€”Feature fusion, channel-spatial attention, densereceptive field, saliency detection, surface defects.This work was supported in part by National Key R&D Program of Chinaunder Grant 2021YFB3301504, in part by the National Natural Science Foun-dation of China under Grant 62172371, U21B2037, 62036010, 62102370,61903341, 62106232, in part by China Postdoctoral Science Foundation underGrant 2021TQ0301, and in part by Foundation for University Key Researchof Henan Province (21A520040, 21A520002), Hangzhou Innovation Institute,Beihang University (NO. 2020-Y4-A-020), and CAAI-Huawei MindSporeOpenFund. (Corresponding author: Jianwei Niu, Mingliang Xu .)Xiaoheng Jiang, Yang Lu, Ke Wang, Shuai Guo, and Mingliang Xu arewith the School of Computer and Artificial Intelligence, Zhengzhou Univer-sity, Engineering Research Center of Intelligent Swarm Systems, Ministryof Education, National Supercomputing Center in Zhengzhou, Zhengzhou450001, China (e-mail: jiangxiaoheng@zzu.edu.cn; ieylu@zzu.edu.cn; iek-wang@zzu.edu.cn; iesguo@zzu.edu.cn; iexumingliang@zzu.edu.cn).Feng Yan is with the School of Computer and Artificial Intelligence,Zhengzhou University, Zhengzhou 450001, China (ieyanfeng@163.com).Tianzhu Zhang is with the School of Information Science and Technology,University of Science and Technology of China, Hefei 230026, China (e-mail:tzzhang@ustc.edu.cn).Yanwei Pang is with the School of Electrical Automation and Infor-mation Engineering, Tianjin University, Tianjin 300072, China (e-mail:pyw@tju.edu.cn).Jianwei Niu is with the State Key Laboratory of Virtual Reality Technologyand Systems, School of Computer Science and Engineering, Beihang Univer-sity, Beijing 100191, China, and Hangzhou Innovation Institute of BeihangUniversity, Hangzhou 310051, China (e-mail: niujianwei@buaa.edu.cn).Fig. 1. Challenges of surface defect inspection. (a) and (b) defects withdifferent scales. (c) defects with low contrast. (a) and (d) interference factorsin the background. The defects and interference factors are represented by redand yellow rectangles, respectively.I. I NTRODUCTIONSURFACE defect inspection is a key task in the process ofindustrial production and is essential for product qualitycontrol. Compared with the manual defect inspection methods,computer vision based automatic defect inspection technolo-gies have become more popular in industrial production due totheir superior defect inspection performance with faster speedand higher accuracy.Traditional defect inspection approaches generally considerthe surface defect inspection as a texture analysis issue and ex-ploit several classic strategies such as texture filters [1], texturestatistics [2], [3], texture modeling [4], and texture structure[5]. These methods rely heavily on specific texture informationand work well when the defects are simple. However, the sur-face defects in real industrial scenes usually exhibit complexityand diversity in appearance and scale, which brings a hugechallenge for accurate defect inspection. Fig. 1 demonstratesseveral typical issues about surface defect inspection, includingscale variation, low contrast, and background interference. Thered and yellow rectangles in Fig. 1 represent the defects andbackground interference, respectively. Fig. 1 (a) and (b) showarXiv:2402.02797v1 [cs.CV] 5 Feb 2024IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 2that the defects vary largely in scale. Some surface defectsare very small and have less than 80 pixels in a 256 Ã— 256image, as shown in Fig. 1 (a). Fig. 1 (c) shows the lowcontrast between the defects and the background caused byinappropriate lighting conditions. Fig. 1 (a) and (d) show thatthere exist some interference factors in the background whichare very similar to the defects and are hard to discriminate.Recently, deep learning methods based on convolutionalneural network (CNN) have made great progress in manycomputer vision tasks such as image classification [6]â€“[8],object detection [9]â€“[11], image segmentation [12]â€“[14], andso on. These methods are designed for general objects and cannot directly generalize to surface defect inspection due to theabove mentioned challenges. To handle these challenges, re-searchers have designed CNN-based models that target surfacedefect inspection, such as the region-level defect inspectionmethods [15]â€“[19] and the pixel-level ones [20]â€“[24]. Amongthese works, the pixel-level methods can provide more detailedinformation about defects, such as boundary, shape, and size.Most of these methods adopt the encoder-decoder structure asthe basic backbone, in which the decoder can be regardedas the fusion process of high-level features from the toplayers and low-level features from the corresponding bottomlayers. The high-level features contain more abstract semanticinformation, while the low-level features contain more finedetails. The combination of the two-level features is beneficialto defect inspection. However, these methods still suffer froma certain amount of inspection errors when the defects showweak appearances, which are usually characterized by lowcontrast, small area, or subtle scratch. That is mainly becausethese methods like [21], [22], [24] simply adopt direct additionor concatenation operations to combine low-level and high-level features, in which the features related to defects are proneto be drowned by the background during feature fusion.To solve this problem, we present a joint attention-guidedfeature fusion (JAFF) module, which can adaptively reservefeatures of defects during feature fusion. JAFF first computesa channel-spatial attention map using the high-level featuresand then uses it to refine the corresponding low-level features.Finally, JAFF concatenates the refined low-level features andhigh-level features in channel dimension. The high-level fea-tures are used to generate the attention map based on thefact that they contain rich semantic information about thedefects. As a result, the obtained attention map can emphasizethe most meaningful low-level defect features and suppressbackground noise during feature fusion, resulting in robustdefect-focused features. In addition, context information isalso crucial in defect detection, especially for those defects ofvarious scales. As the scale of defects changes significantly, thesize of the receptive field should change accordingly. To handlethis problem, we present a dense receptive field (DRF) moduleto capture rich local context information with dense receptivefields, as well as global context information. DRF utilizesthe multi-receptive-field (MRF) units connected densely topromote the multi-scale representation ability of features.Based on the proposed JAFF module and DRF module,we develop the joint attention-guided feature fusion network(JAFFNet) for saliency detection of surface defects. In sum-mary, the main contributions are as follows:1) We develop a joint attention-guided feature fusion net-work (JAFFNet) for saliency detection of surface defectsby introducing two plug-and-play modules, which canachieve end-to-end defect detection.2) We present a joint attention-guided feature fusion (JAFF)module to effectively fuse high-level and low-levelfeatures. It is able to select valuable low-level defectfeatures and suppress background interference duringfeature fusion via the learned joint channel-spatial at-tention map.3) We present a dense receptive field (DRF) module tocapture context information with larger and denser scaleranges. It exploits rich context information by denselyconnecting a series of multi-receptive-field units and canhandle defects with various scales.4) The experiments on three publicly available surface de-fect datasets, including SD-saliency-900, DAGM 2007,and Magnetic Tile, demonstrate that the proposedmethod not only achieves promising defect detectionperformance but also reaches a real-time detection speedof 66 FPS.II. R ELATED WORKSA. Traditional defect inspection methodsMost traditional surface defect inspection methods are basedon texture analysis, which can be broadly classified intofour categories: filter-based, statistic-based, model-based, andstructure-based approaches. Specifically, the filter-based meth-ods analyze texture features through filters, such as Fouriertransform, Gabor transform [1], and Wavelet transform. Thestatistic-based methods analyze texture features through sta-tistical distribution characteristics of the image, such as gray-level co-occurrence matrix (GLCM) [2], local binary pattern(LBP) [3]. The model-based methods describe texture featuresthrough statistics of model parameters, such as the randomfield model, and fractal model [4]. The structure-based ap-proaches analyze texture features through texture primitivesand spatial placement rules, such as [5]. And these methodsare most customized for specific types of defects, with poorreusability and generalization ability. In addition, these meth-ods cannot effectively deal with complicated defects.B. Deep-learning-based defect inspection methodsCompared with traditional surface defect inspection meth-ods, deep-learning-based defect inspection methods are ableto handle defects with weak characteristics and complexbackground, and show superiority in complex scenes. And webroadly divide these methods into two categories: region-leveland pixel-level defect inspection methods.1) Region-level inspection methods: These methods locatedefects by bounding boxes. To improve the defect detectionability of the model, He et al. [15] first integrate multi-levelfeatures into one feature and then feed it into the regionproposal network to generate high-quality defect proposals.Wei et al. [16] incorporate the attention-related visual gainIEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 3Fig. 2. Architecture of the proposed network. Our model consists of an encoder and a decoder, where we obtain multi-level features with channels 64, 128,256, 512, and 512 from five encoding stages E1 âˆ¼ E5, respectively. And D1 âˆ¼ D4 represent four decoding stages with each including a joint attention-guidedfeature fusion (JAFF) module and a convolution block. And the JAFF focuses on the fusion of high-level and low-level features. It incorporates a dual attentionmodule consisting of a channel attention branch (CAB) and a spatial attention branch (SAB) to generate the learned channel-spatial attention map that providesguidance for feature fusion. The dense receptive field (DRF) module after the encoder is used to capture dense context information. And the â€œDSâ€ and â€œrâ€denote depthwise separable convolution and rate of dilated convolution, respectively.mechanism into the Faster RCNN model to improve thediscrimination ability of small defects. However, these detec-tors obtain bounding boxes based on region proposals, withhigh accuracy but slow speed. Therefore, Cui et al. [17]design a fast and accurate detector called SDDNet, whichdetects small defects by passing fine-grained details of low-level features to all deep features. Su et al. [18] adopt anovel attention module (RCAG) to fuse multi-scale features,with the aim of emphasizing defect features and suppressingbackground noise. Different from [17] and [18], Tu et al. [19]achieve accurate defect detection by adopting CIoU loss andintroducing the Gaussian function to estimate the coordinatesof the prediction boxes.2) Pixel-level inspection methods: These methods can pro-vide more structural details of defects than region-level meth-ods, such as boundary, shape, and size. It is essential foraccurate defect detection to capture and integrate multiplecontext information effectively. To this end, Huang et al.[20] apply an atrous spatial pyramid pooling (ASPP) in theproposed lightweight defect segmentation network to capturemultiple context information. Zhang et al. [21] integrate mul-tiple context information through the pyramid pooling module(PPM) and attention module, with the aim of enhancing defectfeatures and filtering out noise. Li et al. [22] integrate multi-scale features from encoder blocks step-by-step, which se-quentially fuses two adjacent scale features and three adjacentscale features. In addition, the attention mechanism is alsooften used in defect segmentation to address those defectswith complex background. For example, Song et al. [23]incorporate the attention mechanism into the model to steerit to focus more on defect features. Zhou et al. [24] introducedense attention cues into the decoder to make it more defect-focused.Different from these existing methods, we propose a jointattention-guided feature fusion network for saliency detectionof surface defects. Specifically, we design two modules toimprove the defect detection performance of encoder-decoderarchitecture. One is called JAFF module, which is used ateach decoding stage to retain more defect features during thefusion of low-level and high-level features. The other is calledDRF module, which is embedded after the fifth encodingstage to capture dense context information and strengthen therepresentation ability of deep features. And the proposed twomodules greatly improve defect detection performance of thenetwork in complex scenes.C. Attention Mechanism in CNNsThe attention mechanism can selectively focus on importantinformation while ignoring less useful information, which isimportant for understanding complex scenes. Hu et al. [25]first propose channel attention and perform adaptive featureIEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT, VOL. XX, NO. XX, XX 2022 4recalibration by explicitly modeling global information. Dueto the limitation of channel attention, Woo et al. [26] proposethe convolutional block attention module (CBAM) whichapplies both channel-wise and spatial attention in sequential.CBAM not only introduces spatial attention but also introducesboth max-pooled and average-pooled features in the spatialaxis into channel attention. Park et al. [27] also design the";
    
    //std::string prompt2 = "Deep Learning Based Regression and Multi-classModels for Acute Oral T oxicity Prediction withAutomatic Chemical Feature ExtractionY oujun Xu,â€  Jianfeng Pei,âˆ—,â€  and Luhua Lai âˆ—,â€ ,â€¡,Â¶â€ Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, PekingUniversity, Beijing 100871, Chinaâ€¡Beijing National Laboratory for Molecular Sciences, State Key Laboratory for StructuralChemistry of Unstable and Stable Species, Col lege of Chemistry and MolecularEngineering, Peking University, Beijing 100871, ChinaÂ¶Peking-T singhua Center for Life Sciences, Peking University, Beijing 100871, ChinaE-mail: jfpei@pku.edu.cn; lhlai@pku.edu.cnFax: (+86)10-62759595; (+86)10-62751725AbstractMedian lethal death, LD 50, is a general indicator of compound acute oral toxicity(AOT). V ariousin silico methods were developed for AOT prediction to reduce costsand time. In this study , we developed an improved molecular graph encoding convolu-tional neural networks (MGE-CNN) framework to construct three types of high-qualityAOT models: regression model (deepAOT-R), multi-classification model (deepAOT-C) and multi-task (deepAOT-CR). These predictive models highly outperformed pre-viously reported models. F or the two external datasets containing 1673 (test set I) and375 (test set II) compounds, the R2 and mean absolute error (MAE) of deepAOT-Ron the test set I were 0.864 and 0.195, and the prediction accuracy of deepAOT-C1arXiv:1704.04718v3 [stat.ML] 4 May 2017was 95.5% and 96.3% on the test set I and II, respectively . The two external pre-diction accuracy of deepAOT-CR is 95.0% and 94.1%, while the R2 and MAE are0.861 and 0.204 for test set I, respectively . W e then performed forward and backwardexploration of deepAOT models for deep fingerprints, which could support shallowmachine learning methods more efficiently than traditional fingerprints or descriptors.W e further performed automatic feature learning, a key essence of deep learning, tomap the corresponding activation values into fragment space and derive AOT-relatedchemical substructures by reverse mining of the features. Our deep learning frameworkfor AOT is generally applicable in predicting and exploring other toxicity or propertyendpoints of chemical compounds. The two deepAOT models are freely available athttp://www.pkumdl.cn/DLAOT/DLAOThome.php.IntroductionEvaluating chemical acute toxicity is important in avoiding potential harmful effects of com-pounds on human health. LD50, the dose of a chemical that causes a 50% death rate in testanimals after administration of a single dose,1 is a general indicator used to measure theacute toxicity of a compound.In vivo experiments of animal tests are required to accuratelydetermine acute chemical toxicity, although these procedures are complicated, costly, andtime-consuming. In addition, due to animal rights, LD50 testing of animals is highly con-troversial.2 Therefore, new reliablein silico methods need to be developed in comparison tostandard in vivo experiments in predicting chemical acute toxicity.Currently, many quantitative structure-property relationship (QSPR) models have beendeveloped to predict acute rodent toxicity of organic chemicals. In these studies, there arevarious mathematical methods applied to construct regression models (RMs) and classifica-tion models (CMs), such as multiple linear regression (MLR),3â€“6 linear regression,7,8 neuralnetwork (NN),9â€“12 k nearest neighbors,13,14 random forest (RF),13,14 hierarchical cluster-ing,13 support vector machine (SVM),14,15 relevance vector machine (RVM),14 and local lazy2learning (LLL).16 In terms of RMs, Lu et al. 16 constructed prediction models using theLLL method, which yielded a maximized linear correlation coefficient (R2) for large testsets. The R 2 of consensus RM based on LLL was 0.608 for â€œSet_3874â€. Leiet al. 14 ar-gued that this method relies on prior knowledge of the query neighbour experimental data,such that the actual prediction capability was associated with the chemical diversity andstructural coverage of the training set. However, machine learning methods have demon-strated potential in establishing complex QSPRs for data sets that contain diverse rangesof molecular structures and mechanisms. Thus, Leiet al. employed RVM combined withother methods (k nearest neighbor, RF, SVMetc.) to construct a consensus RM for pre-dicting AOT in rat. The predictive R2 for the external test set (of 2736 compounds) was0.69. Li et al. 15 suggested that a multi-classification model (MCM) might be more intu-itive in toxicity estimation than a regression model (RM), as a toxic classification is easierto interpret. According to the classification criterion of the U.S. Environmental ProtectionAgency (EPA) (category I: (0, 50]; category II: (50, 500]; category III: (500, 5000]; categoryIV: (5000, +âˆž); mg/kg), MCM with one-vs-one (SVMOAO) and binary tree SVM methodswere developed based on different molecular fingerprints or descriptors, yielding an accuracyof 83.2% for validation set (2049 compounds), 83.0% for test set I (1678 compounds), and89.9% for test set II (375 compounds). In chemoinformatics research, high-quality QSPRmodels with interpretable relationship between chemical properties and chemical featuresare especially welcome. However, predictive power and interpretability of QSPR models aretwo different objectives that are difficult to achieve simultaneously.17 We can identify someimportant features from weights within linear-based models (MLR, linear-SVMetc.) withlow predictive power. These features may be mapped into the corresponding fragments inchemical structural space. With statistics and sensitivity analysis18 of input features (ratherthan intuitive analysis of the constructed models), â€œblack boxâ€ models (NN, kernal-SVM,RF) with high predictive power can extract human understandable knowledge. These abovemethods depend on complicated molecular representation (MR) using chemical knowledge3and intuition.Appropriate MRs that are related to biological activities or other experimental end-points19,20 are crucial in developing accurate prediction models. Automatic representationwould greatly simplify and accelerate the development of QSPR models. The emergenceof deep learning techniques21â€“23 may provide possible solutions to this problem. Insteadof using application-specific molecular descriptors or fingerprints (e.g. ECFP,24 MACCS,25etc.), the AOT issue can be resolved using raw and pertinent features without manual inter-vention or selection. The two-dimensional (2D) structure of a small molecule is equivalentto an undirected graph, with atoms as nodes and bonds as edges. Encoding an undirectedgraph can be converted into a problem of fitting a graph into a fix-sized vector. Currently,two types of methods, sink-based and source-based, have been used for encoding undirectedgraphs with NNs. In the sink-based method, by defining a root node, all the other nodes inthe graph proceed towards the root. The internal process is embedded with multiple NNs inrepresenting the information transmission between nodes, after which the final informationis extracted from the root node. The sink-based method was demonstrated to be feasibleand practical.26,27 However, there are no reasonable explanation for hidden-layer features indeep learning model such that the model seems â€œblackâ€. In the source-based method, similarto the Morgan algorithm28 and extended-connectivity fingerprints (ECFP),24 when startingfrom an initial node and diffusing outward layer-by-layer with multiple NNs, the informa-tion can be extracted step-wise from each layer. Recently, Duvenaudet al. 29 and Kearneset al. 30 first used CNNs to successfully implement similar source-based methods. The state-of-the-art performance on some public datasets31â€“36 suggests that molecular graph encoding(MGE) methods based on multiple NNs have potential in the field of chemoinformatics. Inprincipal, MGE is an ideal representation of chemical structures without information loss.Actually, intermediate features within deep learning models are far from random, unin-terpretable patterns. By visualizing the activity of hidden layers based on well-performedmodels from ImageNet 2012, Zeileret al. presented a nested hierarchy of concepts, with each4concept defined in relation to simpler concepts (pixelsâ†’ edges â†’ corners and contoursâ†’object parts â†’ object identity),37 which is an efficient illustration of a deep learning-basedCNN model. Different compounds may play different functions in the living organisms.Simple concepts of atoms and bonds are combined into more complex concepts of structuralfragments, then integrated into high concepts of different functions (atoms and bondsâ†’fragments â†’ functions). By designing ECFP-based CNN architecture, the internal featureswere visualized by Duvenaudet al. as the corresponding fragments,29 providing a betterunderstanding of a deep learning-based QSPR model. Despite of a number of successfulapplication examples in chemoinformatics studies using MGE, the following points need tobe improved for better prediction and easy interpretation: 1) hyperparameters, 2) trainingand prediction strategy, 3) multi-output problem, 4) model interpretation. The approachbased on CNN with these above improvements was referenced hereafter as â€œMGE-CNNâ€.Here we used MGE-CNN framework (shown in Figure 1A) to construct AOT models. Inorder to develop high-quality deep learning models, namely deepAOT, RMs were constructedusing the reported largest AOT dataset from Liet al. ,15 including experimental oral LD50values for chemicals in rat. Based on the U.S. EPA criterion for the AOT category, MCMswere also developed to predict chemical toxicity categories. Two external test datasets wereused to estimate the predictive power of RMs and MCMs. The consensus RM and the bestMCM were called â€œdeepAOT-Râ€ and â€œdeepAOT-Câ€, respectively. We demonstrated that thedeepAOT-R and deepAOT-C models outperformed the previous reported models whetherit was a regression or classification problem. Given the relevance of both tasks, multi-task deepAOT-CR model was developed for improving the consistency of regression andclassification models. Further analysis was performed by forward and backward exploration(Figure 1A) of internal features (referred to as deep fingerprints) directly extracted from ourmodels to interpret the RMs and MCMs. The forward exploration was used to determinethe predictability of fingerprints, while the backward exploration was used to understandand explore structural alerts concerning AOT. In view of end-to-end learning, the MGE-5CNN framework in this study can also be applied to predicting and exploring other toxicityendpoints induced by small molecules in complex systems.Figure 1: (A) Schematic diagram of MGE-CNN architecture. â€œConvâ€ represents the convo-lution kernel and the 6 kernels rely on the degree of each atom. (B) Overview of pseudocodein Algorithm 1. (C) The assessment method of Sens and PPV for each of classes and ACCof all the classes. Sens I is equal to the number of the higher black region divided by thesum of the bottom black region, which was identical with PPV I. The roman letters â€œI, II,III, IVâ€ represent toxicity categories.Materials and MethodsMGE-CNNThe MGE-CNN architecture takes the canonical SMILES string of a small molecule asinput, and produces a score capable of describing a value or label about toxicity. Figure 1Aand 1B show this architecture and its high-level pseudocode with the steps of MGE-CNN6feedforward process. Firstly, given an input SMILES string (x), a molecular structural graphis converted by the RDKit toolbox.38 The sub-graph from each layer (or iteration) is encodedinto a fixed-sized vectorzLl âˆˆ R|F P L| l âˆˆ {1, 2, ..., |F P D|}, then these vectors are summedas zx âˆˆ R|F P L| representing this molecule. Thenzx is used as input of the subsequent neuralnetwork in the output layer for executing the following operation:score = f(zxWoutputH + boutputH )WoutputO + boutputO (1)where WoutputH âˆˆ R|F P L|Ã—|HLS| is the weight matrix of hidden layer in the output layer,WoutputO âˆˆ R|HLS|Ã—doutall is the weight matrix of output layer in the output layer, andboutputH âˆˆR1Ã—|HLS| and boutputO âˆˆ R1Ã—doutall are bias terms. doutall = 1 for RMs, doutall = 4 for MCMs. The4-dimensional vector is transformed withsoftmax function representing the probability offour classes. p(i|x) = escore(x)iâˆ‘4j=1 escore(x)j is the probability of categoryi, where score(x)i is thescore for categoryi.The MGE-CNN has three main advantages: 1) The input information of initial atomsand bonds is very similar to that of ECFP. The atom information contains atomic type, itsdegree, its implicit valence, the number of attached H atoms and aromatic atoms. The bondinformation is relied on bond type (single, double, triple, aromatic, conjugated or in-a-ring).These atom and bond-level information is used to characterize the surrounding chemicalenvironment of each atom as completely as possible. All of these information can be calcu-lated using RDKit. 2) Molecular graphs are encoded with CNN, which makes informationtransmission become continuous and constructs an end-to-end differential system. In suchcase, we can perform gradient descent with a large number of labelled data to optimize thissystem. During the training process, automatic feature learning is implemented, avoidingmanual feature selection. 3) The feature learning and model construction processes are inte-grated together. Once the model is well-trained with supervised learning, these fingerprintsare also learned.The following improvements for better prediction and easy interpretation in our system7were adopted: 1) For hyperparameter optimization in the AOT system, we empirically foundthat the default settings (Î²1 = 0 .9, Î²2 = 0 .999) for adaptive moment estimation (Adam)would be more helpful than those provided by the Duvenaudet al. 2) To avoid providing thetraining examples in a meaningful order (which may bias the optimization algorithm and leadto over-fitting), the trick of â€œshufflingâ€39 was added into the whole training process. 3) Thepopular methods ofsoftmax function andcross-entropy loss function were introduced to meetthe requirements of multi-classification task. 4) Regression and classification tasks were takeninto consideration simultaneously for developing the multi-task model. 5) To further explainthe rationality of our models, deep fingerprints directly extracted from well-built models wereused to construct shallow machine learning models. The structural fragments with the largestcontribution (arg min (linear regression coefficientÃ— activation values) ) to chemical toxicitywere drawn out for comparison with the reported toxicity alerts, while the original MGE onlyconsidered those coefficients. 6) The mean and standard deviation of the training set for eachlayer are calculated for normalizing validation or external test set, reducing the bias caused bydifferent distributions. Based on these, the MGE-CNN was employed to construct RMs andCMs for estimating AOT in rat, as shown in Figure 1A. During â€œModel constructionâ€, thesemodels were trained, validated and externally challenged. During â€œFingerprint analysisâ€,the well-trained deep fingerprints of small molecules were used to develop shallow models,MLR and SVM, to predict AOT values or labels. Simultaneously, the most relevant featureamong deep fingerprint for each compound was calculated based on linear regression withleast squares fitting, then traced back to the atomic level, and mapped onto AOT activationfragments. These activated fragments were then used to compare with reported toxicityalerts (TAs) to validate the inference capability for TAs.T raining deepAOT modelsThe approach for training deepAOT models includes hyperparameter optimization methodsand gradient descent optimization algorithms.8Hyperparameter optimizationDeep learning is a dramatic improvement in many fields,21 in particular for CNNs,40â€“42 which";
    std::string prompt2 = "è¯·æ€»ç»“ä¸‹é¢çš„æ–‡æ¡£ï¼Œè¾“å‡ºæ‘˜è¦å’Œå…³é”®è¯:Deep Learning Based Regression and Multi-classModels for Acute Oral T oxicity Prediction withAutomatic Chemical Feature ExtractionY oujun Xu,â€  Jianfeng Pei,âˆ—,â€  and Luhua Lai âˆ—,â€ ,â€¡,Â¶â€ Center for Quantitative Biology, Academy for Advanced Interdisciplinary Studies, PekingUniversity, Beijing 100871, Chinaâ€¡Beijing National Laboratory for Molecular Sciences, State Key Laboratory for StructuralChemistry of Unstable and Stable Species, Col lege of Chemistry and MolecularEngineering, Peking University, Beijing 100871, ChinaÂ¶Peking-T singhua Center for Life Sciences, Peking University, Beijing 100871, ChinaE-mail: jfpei@pku.edu.cn; lhlai@pku.edu.cnFax: (+86)10-62759595; (+86)10-62751725AbstractMedian lethal death, LD 50, is a general indicator of compound acute oral toxicity(AOT). V ariousin silico methods were developed for AOT prediction to reduce costsand time. In this study , we developed an improved molecular graph encoding convolu-tional neural networks (MGE-CNN) framework to construct three types of high-qualityAOT models: regression model (deepAOT-R), multi-classification model (deepAOT-C) and multi-task (deepAOT-CR). These predictive models highly outperformed pre-viously reported models. F or the two external datasets containing 1673 (test set I) and375 (test set II) compounds, the R2 and mean absolute error (MAE) of deepAOT-Ron the test set I were 0.864 and 0.195, and the prediction accuracy of deepAOT-C1arXiv:1704.04718v3 [stat.ML] 4 May 2017was 95.5% and 96.3% on the test set I and II, respectively . The two external pre-diction accuracy of deepAOT-CR is 95.0% and 94.1%, while the R2 and MAE are0.861 and 0.204 for test set I, respectively . W e then performed forward and backwardexploration of deepAOT models for deep fingerprints, which could support shallowmachine learning methods more efficiently than traditional fingerprints or descriptors.W e further performed automatic feature learning, a key essence of deep learning, tomap the corresponding activation values into fragment space and derive AOT-relatedchemical substructures by reverse mining of the features. Our deep learning frameworkfor AOT is generally applicable in predicting and exploring other toxicity or propertyendpoints of chemical compounds. The two deepAOT models are freely available athttp://www.pkumdl.cn/DLAOT/DLAOThome.php.IntroductionEvaluating chemical acute toxicity is important in avoiding potential harmful effects of com-pounds on human health. LD50, the dose of a chemical that causes a 50% death rate in testanimals after administration of a single dose,1 is a general indicator used to measure theacute toxicity of a compound.In vivo experiments of animal tests are required to accuratelydetermine acute chemical toxicity, although these procedures are complicated, costly, andtime-consuming. In addition, due to animal rights, LD50 testing of animals is highly con-troversial.2 Therefore, new reliablein silico methods need to be developed in comparison tostandard in vivo experiments in predicting chemical acute toxicity.Currently, many quantitative structure-property relationship (QSPR) models have beendeveloped to predict acute rodent toxicity of organic chemicals. In these studies, there arevarious mathematical methods applied to construct regression models (RMs) and classifica-tion models (CMs), such as multiple linear regression (MLR),3â€“6 linear regression,7,8 neuralnetwork (NN),9â€“12 k nearest neighbors,13,14 random forest (RF),13,14 hierarchical cluster-ing,13 support vector machine (SVM),14,15 relevance vector machine (RVM),14 and local lazy2learning (LLL).16 In terms of RMs, Lu et al. 16 constructed prediction models using theLLL method, which yielded a maximized linear correlation coefficient (R2) for large testsets. The R 2 of consensus RM based on LLL was 0.608 for â€œSet_3874â€. Leiet al. 14 ar-gued that this method relies on prior knowledge of the query neighbour experimental data,such that the actual prediction capability was associated with the chemical diversity andstructural coverage of the training set. However, machine learning methods have demon-strated potential in establishing complex QSPRs for data sets that contain diverse rangesof molecular structures and mechanisms. Thus, Leiet al. employed RVM combined withother methods (k nearest neighbor, RF, SVMetc.) to construct a consensus RM for pre-dicting AOT in rat. The predictive R2 for the external test set (of 2736 compounds) was0.69. Li et al. 15 suggested that a multi-classification model (MCM) might be more intu-itive in toxicity estimation than a regression model (RM), as a toxic classification is easierto interpret. According to the classification criterion of the U.S. Environmental ProtectionAgency (EPA) (category I: (0, 50]; category II: (50, 500]; category III: (500, 5000]; categoryIV: (5000, +âˆž); mg/kg), MCM with one-vs-one (SVMOAO) and binary tree SVM methodswere developed based on different molecular fingerprints or descriptors, yielding an accuracyof 83.2% for validation set (2049 compounds), 83.0% for test set I (1678 compounds), and89.9% for test set II (375 compounds). In chemoinformatics research, high-quality QSPRmodels with interpretable relationship between chemical properties and chemical featuresare especially welcome. However, predictive power and interpretability of QSPR models aretwo different objectives that are difficult to achieve simultaneously.17 We can identify someimportant features from weights within linear-based models (MLR, linear-SVMetc.) withlow predictive power. These features may be mapped into the corresponding fragments inchemical structural space. With statistics and sensitivity analysis18 of input features (ratherthan intuitive analysis of the constructed models), â€œblack boxâ€ models (NN, kernal-SVM,RF) with high predictive power can extract human understandable knowledge. These abovemethods depend on complicated molecular representation (MR) using chemical knowledge3and intuition.Appropriate MRs that are related to biological activities or other experimental end-points19,20 are crucial in developing accurate prediction models. Automatic representationwould greatly simplify and accelerate the development of QSPR models. The emergenceof deep learning techniques21â€“23 may provide possible solutions to this problem. Insteadof using application-specific molecular descriptors or fingerprints (e.g. ECFP,24 MACCS,25etc.), the AOT issue can be resolved using raw and pertinent features without manual inter-vention or selection. The two-dimensional (2D) structure of a small molecule is equivalentto an undirected graph, with atoms as nodes and bonds as edges. Encoding an undirectedgraph can be converted into a problem of fitting a graph into a fix-sized vector. Currently,two types of methods, sink-based and source-based, have been used for encoding undirectedgraphs with NNs. In the sink-based method, by defining a root node, all the other nodes inthe graph proceed towards the root. The internal process is embedded with multiple NNs inrepresenting the information transmission between nodes, after which the final informationis extracted from the root node. The sink-based method was demonstrated to be feasibleand practical.26,27 However, there are no reasonable explanation for hidden-layer features indeep learning model such that the model seems â€œblackâ€. In the source-based method, similarto the Morgan algorithm28 and extended-connectivity fingerprints (ECFP),24 when startingfrom an initial node and diffusing outward layer-by-layer with multiple NNs, the informa-tion can be extracted step-wise from each layer. Recently, Duvenaudet al. 29 and Kearneset al. 30 first used CNNs to successfully implement similar source-based methods. The state-of-the-art performance on some public datasets31â€“36 suggests that molecular graph encoding(MGE) methods based on multiple NNs have potential in the field of chemoinformatics. Inprincipal, MGE is an ideal representation of chemical structures without information loss.Actually, intermediate features within deep learning models are far from random, unin-terpretable patterns. By visualizing the activity of hidden layers based on well-performedmodels from ImageNet 2012, Zeileret al. presented a nested hierarchy of concepts, with each4concept defined in relation to simpler concepts (pixelsâ†’ edges â†’ corners and contoursâ†’object parts â†’ object identity),37 which is an efficient illustration of a deep learning-basedCNN model. Different compounds may play different functions in the living organisms.Simple concepts of atoms and bonds are combined into more complex concepts of structuralfragments, then integrated into high concepts of different functions (atoms and bondsâ†’fragments â†’ functions). By designing ECFP-based CNN architecture, the internal featureswere visualized by Duvenaudet al. as the corresponding fragments,29 providing a betterunderstanding of a deep learning-based QSPR model. Despite of a number of successfulapplication examples in chemoinformatics studies using MGE, the following points need tobe improved for better prediction and easy interpretation: 1) hyperparameters, 2) trainingand prediction strategy, 3) multi-output problem, 4) model interpretation. The approachbased on CNN with these above improvements was referenced hereafter as â€œMGE-CNNâ€.Here we used MGE-CNN framework (shown in Figure 1A) to construct AOT models. Inorder to develop high-quality deep learning models, namely deepAOT, RMs were constructedusing the reported largest AOT dataset from Liet al. ,15 including experimental oral LD50values for chemicals in rat. Based on the U.S. EPA criterion for the AOT category, MCMswere also developed to predict chemical toxicity categories. Two external test datasets wereused to estimate the predictive power of RMs and MCMs. The consensus RM and the bestMCM were called â€œdeepAOT-Râ€ and â€œdeepAOT-Câ€, respectively. We demonstrated that thedeepAOT-R and deepAOT-C models outperformed the previous reported models whetherit was a regression or classification problem. Given the relevance of both tasks, multi-task deepAOT-CR model was developed for improving the consistency of regression andclassification models. Further analysis was performed by forward and backward exploration(Figure 1A) of internal features (referred to as deep fingerprints) directly extracted from ourmodels to interpret the RMs and MCMs. The forward exploration was used to determinethe predictability of fingerprints, while the backward exploration was used to understandand explore structural alerts concerning AOT. In view of end-to-end learning, the MGE-5CNN framework in this study can also be applied to predicting and exploring other toxicityendpoints induced by small molecules in complex systems.Figure 1: (A) Schematic diagram of MGE-CNN architecture. â€œConvâ€ represents the convo-lution kernel and the 6 kernels rely on the degree of each atom. (B) Overview of pseudocodein Algorithm 1. (C) The assessment method of Sens and PPV for each of classes and ACCof all the classes. Sens I is equal to the number of the higher black region divided by thesum of the bottom black region, which was identical with PPV I. The roman letters â€œI, II,III, IVâ€ represent toxicity categories.Materials and MethodsMGE-CNNThe MGE-CNN architecture takes the canonical SMILES string of a small molecule asinput, and produces a score capable of describing a value or label about toxicity. Figure 1Aand 1B show this architecture and its high-level pseudocode with the steps of MGE-CNN6feedforward process. Firstly, given an input SMILES string (x), a molecular structural graphis converted by the RDKit toolbox.38 The sub-graph from each layer (or iteration) is encodedinto a fixed-sized vectorzLl âˆˆ R|F P L| l âˆˆ {1, 2, ..., |F P D|}, then these vectors are summedas zx âˆˆ R|F P L| representing this molecule. Thenzx is used as input of the subsequent neuralnetwork in the output layer for executing the following operation:score = f(zxWoutputH + boutputH )WoutputO + boutputO (1)where WoutputH âˆˆ R|F P L|Ã—|HLS| is the weight matrix of hidden layer in the output layer,WoutputO âˆˆ R|HLS|Ã—doutall is the weight matrix of output layer in the output layer, andboutputH âˆˆR1Ã—|HLS| and boutputO âˆˆ R1Ã—doutall are bias terms. doutall = 1 for RMs, doutall = 4 for MCMs. The4-dimensional vector is transformed withsoftmax function representing the probability offour classes. p(i|x) = escore(x)iâˆ‘4j=1 escore(x)j is the probability of categoryi, where score(x)i is thescore for categoryi.The MGE-CNN has three main advantages: 1) The input information of initial atomsand bonds is very similar to that of ECFP. The atom information contains atomic type, itsdegree, its implicit valence, the number of attached H atoms and aromatic atoms. The bondinformation is relied on bond type (single, double, triple, aromatic, conjugated or in-a-ring).These atom and bond-level information is used to characterize the surrounding chemicalenvironment of each atom as completely as possible. All of these information can be calcu-lated using RDKit. 2) Molecular graphs are encoded with CNN, which makes informationtransmission become continuous and constructs an end-to-end differential system. In suchcase, we can perform gradient descent with a large number of labelled data to optimize thissystem. During the training process, automatic feature learning is implemented, avoidingmanual feature selection. 3) The feature learning and model construction processes are inte-grated together. Once the model is well-trained with supervised learning, these fingerprintsare also learned.The following improvements for better prediction and easy interpretation in our system7were adopted: 1) For hyperparameter optimization in the AOT system, we empirically foundthat the default settings (Î²1 = 0 .9, Î²2 = 0 .999) for adaptive moment estimation (Adam)would be more helpful than those provided by the Duvenaudet al. 2) To avoid providing thetraining examples in a meaningful order (which may bias the optimization algorithm and leadto over-fitting), the trick of â€œshufflingâ€39 was added into the whole training process. 3) Thepopular methods ofsoftmax function andcross-entropy loss function were introduced to meetthe requirements of multi-classification task. 4) Regression and classification tasks were takeninto consideration simultaneously for developing the multi-task model. 5) To further explainthe rationality of our models, deep fingerprints directly extracted from well-built models wereused to construct shallow machine learning models. The structural fragments with the largestcontribution (arg min (linear regression coefficientÃ— activation values) ) to chemical toxicitywere drawn out for comparison with the reported toxicity alerts, while the original MGE onlyconsidered those coefficients. 6) The mean and standard deviation of the training set for eachlayer are calculated for normalizing validation or external test set, reducing the bias caused bydifferent distributions. Based on these, the MGE-CNN was employed to construct RMs andCMs for estimating AOT in rat, as shown in Figure 1A. During â€œModel constructionâ€, thesemodels were trained, validated and externally challenged. During â€œFingerprint analysisâ€,the well-trained deep fingerprints of small molecules were used to develop shallow models,MLR and SVM, to predict AOT values or labels. Simultaneously, the most relevant featureamong deep fingerprint for each compound was calculated based on linear regression withleast squares fitting, then traced back to the atomic level, and mapped onto AOT activationfragments. These activated fragments were then used to compare with reported toxicityalerts (TAs) to validate the inference capability for TAs.T raining deepAOT modelsThe approach for training deepAOT models includes hyperparameter optimization methodsand gradient descent optimization algorithms.8Hyperparameter optimizationDeep learning is a dramatic improvement in many fields,21 in particular for CNNs,40â€“42 which";
    /*
    if (_putenv("ONEDNN_PRIMITIVE_CACHE_CAPACITY=0") != 0) {
        throw std::runtime_error("Failed to set environment variable");
    }
    */
    
    // ov::genai::LLMPipeline* pipe = new ov::genai::LLMPipeline(models_path, device);

    for (int i = 0; i < 3; ++i) {
        /*
        std::cout << "zhaohb!!!!" << std::endl;

        STARTUPINFO si;
        PROCESS_INFORMATION pi;
        ZeroMemory(&si, sizeof(si));
        si.cb = sizeof(si);
        ZeroMemory(&pi, sizeof(pi));

        const char* cmdline = "D:\\xsun\\Honor_Test\\samples_bin\\genai_exe.exe";

        if (!CreateProcess(
            cmdline,
            NULL,
            NULL,
            NULL,
            FALSE,
            0,
            NULL,
            NULL,
            &si,
            &pi
            )
         ) {
            std::cout << "failt to create process!!!: " <<  GetLastError() << std::endl;
            return false;
        }

        WaitForSingleObject(pi.hProcess, INFINITE);

        CloseHandle(pi.hProcess);
        CloseHandle(pi.hThread);
        */
        std::cout << "Round: " << i << "\n";
        ov::genai::LLMPipeline* pipe = new ov::genai::LLMPipeline(models_path, device);
        std::cout << "Init pipeline 1 works\n";
        /*
        ov::genai::LLMPipeline* pipe1 = new ov::genai::LLMPipeline(models_path, device);
        std::cout << "Init pipeline 2 works\n";
        */
        //auto prompt_utf8_start = std::chrono::high_resolution_clock::now();
        //std::string prompt_utf8 = EncodeUtils::StringToUTF8String(prompt);
        std::string prompt_utf8 = prompt;
        //auto prompt_utf8_end = std::chrono::high_resolution_clock::now();
        //std::chrono::duration<double, std::milli> dur1_prompt = prompt_utf8_end - prompt_utf8_start;
        //std::cout << "StringToUTF8String takes: " << dur1_prompt.count() << " ms" << std::endl;

        
        {

            //std::string prompt_utf8 = prompt;
            
            //std::cout << "prompt_utf8: " << prompt_utf8 << "\n";
            
            auto start = std::chrono::high_resolution_clock::now();
            pipe->start_chat();
            std::string result = pipe->generate(prompt_utf8, config, streamer);
            //std::string result = pipe->generate(StringToUTF8(prompt), config);
            std::cout << result << "result\n";
            pipe->finish_chat();
            auto end1 = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double, std::milli> dur1 = end1 - start;
            std::cout << "\nE2E Inference time takes: " << dur1.count() << " ms" << std::endl;

            /*
            auto start1 = std::chrono::high_resolution_clock::now();
            pipe1->start_chat();
            std::string result1 = pipe1->generate(prompt_utf8, config, streamer);
            //std::string result = pipe->generate(StringToUTF8(prompt), config);
            std::cout << result1 << "result\n";
            pipe1->finish_chat();
            auto end2 = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double, std::milli> dur2 = end2 - start1;
            std::cout << "\nE2E Inference time takes: " << dur2.count() << " ms" << std::endl;
            */
            /*
            auto prompt1_utf8_start = std::chrono::high_resolution_clock::now();
            //std::string prompt1_utf8 = EncodeUtils::StringToUTF8String(prompt1);
            std::string prompt1_utf8 = prompt1;
            auto prompt1_utf8_end = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double, std::milli> dur2_prompt = prompt1_utf8_end - prompt1_utf8_start;
            std::cout << "StringToUTF8String takes: " << dur2_prompt.count() << " ms" << std::endl;

            //std::string prompt1_utf8 = prompt1;
            //std::cout << "prompt1_utf8: " << prompt1_utf8 << "\n";
            pipe->start_chat();
            std::string result1 = pipe->generate(prompt1_utf8, config, streamer);
            //std::string result1 = pipe->generate(StringToUTF8(prompt1), config);
            //std::cout << result1 << "result\n";
            //std::ofstream outFile1("output1.txt");
            //if (outFile1.is_open()) {
            //    outFile1 << result1; // å°† result1 å†™å…¥æ–‡ä»¶
            //    outFile1.close();    // å…³é—­æ–‡ä»¶
            //    std::cout << "ç»“æžœå·²æˆåŠŸä¿å­˜åˆ° output1.txt" << std::endl;
            //}
            pipe->finish_chat();
            auto end2 = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double, std::milli> dur2 = end2 - end1;
            std::cout << "\nE2E Inference time takes: " << dur2.count() << " ms" << std::endl;

            auto prompt2_utf8_start = std::chrono::high_resolution_clock::now();
            //std::string prompt2_utf8 = EncodeUtils::StringToUTF8String(prompt2);
            std::string prompt2_utf8 = prompt2;
            auto prompt2_utf8_end = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double, std::milli> dur3_prompt = prompt2_utf8_end - prompt2_utf8_start;
            std::cout << "StringToUTF8String takes: " << dur3_prompt.count() << " ms" << std::endl;

            //std::string prompt2_utf8 = prompt2;
            //std::cout << "prompt2_utf8: " << prompt2_utf8 << "\n";
            pipe->start_chat();
            std::string result2 = pipe->generate(prompt2_utf8, config, streamer);
            //std::string result2 = pipe->generate(StringToUTF8(prompt2), config);
            //std::cout << result2 << "result\n";
            pipe->finish_chat();
            auto end3 = std::chrono::high_resolution_clock::now();
            std::chrono::duration<double, std::milli> dur3 = end3 - end2;
            std::cout << "\nE2E Inference time takes: " << dur3.count() << " ms" << std::endl;
            */
        }
        std::cout << "Delete pipe called " << std::endl;
        //pipe->test_release_mem();
        delete pipe;
        //delete pipe1;

        std::cout << "ov::genai::clear_core_device(" << device << ")\n";
        ov::genai::clear_core_device(device);
        
        std::cout << "After delete pipe & unload plugin " << std::endl;
        //delete pipe1;
        //std::cout << " after del pipe1 " << std::endl;
	#ifdef _WIN32
	    Sleep(20000);
	#else
            sleep(20);
	#endif
	
        /*
        auto start1 = std::chrono::high_resolution_clock::now();
        pipe1->start_chat();
        //std::string result1 = pipe1->generate(prompt_utf8, config, streamer);
        //std::string result = pipe->generate(StringToUTF8(prompt), config);
        //std::cout << result1 << "result\n";
        pipe1->finish_chat();
        auto end2 = std::chrono::high_resolution_clock::now();
        std::chrono::duration<double, std::milli> dur2 = end2 - start1;
        std::cout << "\nE2E Inference time takes: " << dur2.count() << " ms" << std::endl;
        */
    }
    // delete pipe;
    //std::thread::sleep(50);
    // Sleep(50000);
}
catch (const std::exception& error) {
    try {
        std::cerr << error.what() << '\n';
    }
    catch (const std::ios_base::failure&) {}
    return EXIT_FAILURE;
}
catch (...) {
    try {
        std::cerr << "Non-exception object thrown\n";
    }
    catch (const std::ios_base::failure&) {}
    return EXIT_FAILURE;
}

